{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens.doc import Doc\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_loc = 'test_dump.bin'\n",
    "train_loc = 'train_dump.bin'\n",
    "invalids = ['PUNCT', 'X', 'EOL', 'SPACE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 6) (2345796, 3)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../data/train.csv').fillna('')\n",
    "test = pd.read_csv('../data/test.csv').fillna('')\n",
    "print train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target = list(train['is_duplicate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read training data\n",
    "Elements $(2n, 2n+1)$ are the questions for pair $n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-16 03:35:02\n",
      "0 2017-05-16 03:35:02\n",
      "10000 2017-05-16 03:35:06\n",
      "20000 2017-05-16 03:35:07\n",
      "30000 2017-05-16 03:35:08\n",
      "40000 2017-05-16 03:35:09\n",
      "50000 2017-05-16 03:35:10\n",
      "60000 2017-05-16 03:35:11\n",
      "70000 2017-05-16 03:35:12\n",
      "80000 2017-05-16 03:35:13\n",
      "90000 2017-05-16 03:35:14\n",
      "100000 2017-05-16 03:35:16\n",
      "110000 2017-05-16 03:35:17\n",
      "120000 2017-05-16 03:35:18\n",
      "130000 2017-05-16 03:35:19\n",
      "140000 2017-05-16 03:35:20\n",
      "150000 2017-05-16 03:35:21\n",
      "160000 2017-05-16 03:35:23\n",
      "170000 2017-05-16 03:35:24\n",
      "180000 2017-05-16 03:35:24\n",
      "190000 2017-05-16 03:35:26\n",
      "200000 2017-05-16 03:35:26\n",
      "210000 2017-05-16 03:35:27\n",
      "220000 2017-05-16 03:35:28\n",
      "230000 2017-05-16 03:35:30\n",
      "240000 2017-05-16 03:35:31\n",
      "250000 2017-05-16 03:35:33\n",
      "260000 2017-05-16 03:35:34\n",
      "270000 2017-05-16 03:35:34\n",
      "280000 2017-05-16 03:35:35\n",
      "290000 2017-05-16 03:35:36\n",
      "300000 2017-05-16 03:35:37\n",
      "310000 2017-05-16 03:35:38\n",
      "320000 2017-05-16 03:35:39\n",
      "330000 2017-05-16 03:35:40\n",
      "340000 2017-05-16 03:35:41\n",
      "350000 2017-05-16 03:35:42\n",
      "360000 2017-05-16 03:35:43\n",
      "370000 2017-05-16 03:35:44\n",
      "380000 2017-05-16 03:35:45\n",
      "390000 2017-05-16 03:35:46\n",
      "400000 2017-05-16 03:35:47\n",
      "410000 2017-05-16 03:35:48\n",
      "420000 2017-05-16 03:35:49\n",
      "430000 2017-05-16 03:35:50\n",
      "440000 2017-05-16 03:35:50\n",
      "450000 2017-05-16 03:35:51\n",
      "460000 2017-05-16 03:35:52\n",
      "470000 2017-05-16 03:35:53\n",
      "480000 2017-05-16 03:35:54\n",
      "490000 2017-05-16 03:35:55\n",
      "500000 2017-05-16 03:35:56\n",
      "510000 2017-05-16 03:35:57\n",
      "520000 2017-05-16 03:35:58\n",
      "530000 2017-05-16 03:35:59\n",
      "540000 2017-05-16 03:36:00\n",
      "550000 2017-05-16 03:36:02\n",
      "560000 2017-05-16 03:36:04\n",
      "570000 2017-05-16 03:36:05\n",
      "580000 2017-05-16 03:36:06\n",
      "590000 2017-05-16 03:36:07\n",
      "600000 2017-05-16 03:36:08\n",
      "610000 2017-05-16 03:36:09\n",
      "620000 2017-05-16 03:36:11\n",
      "630000 2017-05-16 03:36:12\n",
      "640000 2017-05-16 03:36:13\n",
      "650000 2017-05-16 03:36:15\n",
      "660000 2017-05-16 03:36:17\n",
      "670000 2017-05-16 03:36:17\n",
      "680000 2017-05-16 03:36:19\n",
      "690000 2017-05-16 03:36:20\n",
      "700000 2017-05-16 03:36:20\n",
      "710000 2017-05-16 03:36:21\n",
      "720000 2017-05-16 03:36:22\n",
      "730000 2017-05-16 03:36:23\n",
      "740000 2017-05-16 03:36:24\n",
      "750000 2017-05-16 03:36:25\n",
      "760000 2017-05-16 03:36:26\n",
      "770000 2017-05-16 03:36:27\n",
      "780000 2017-05-16 03:36:28\n",
      "790000 2017-05-16 03:36:29\n",
      "800000 2017-05-16 03:36:30\n",
      "2017-05-16 03:36:30\n",
      "<type 'spacy.tokens.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "i = 0\n",
    "print datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "with open(train_loc, 'rb') as file_:\n",
    "    for byte_string in Doc.read_bytes(file_):\n",
    "        if i%10000 == 0: print i, datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        docs.append(Doc(nlp.vocab).from_bytes(byte_string))\n",
    "        i += 1\n",
    "#         if i == 10: break\n",
    "print datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(type(docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DNS,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[5].ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def covertPropn(pos):\n",
    "#     if pos == u'PROPN' or pos == u'PRON':\n",
    "#         return u'NOUN'\n",
    "#     if pos == u'ADP': return u'ADV'\n",
    "#     else: return pos\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import mapping\n",
    "from itertools import product\n",
    "from nltk.corpus import wordnet as wn\n",
    "import numpy as np\n",
    "from nltk.wsd import lesk\n",
    "import copy\n",
    "\n",
    "def sim(s1, s2):\n",
    "    return wn.wup_similarity(s1, s2)\n",
    "    \n",
    "def leskify(lemma, pos, sentence):\n",
    "    mapping = {'NOUN': 'n', 'ADJ':'a', 'ADV':'r', 'VERB':'v', 'PRON':'n', 'ADP':'p', 'DET':'n'}\n",
    "    m = mapping[pos]\n",
    "    l = lesk(sentence, lemma, m)\n",
    "    return l\n",
    "    \n",
    "def wnSim(w1, w2):\n",
    "    fillin = 0\n",
    "    w1 = set([(word.lemma_, covertPropn(word.pos_)) for word in w1])\n",
    "    w2 = set([(word.lemma_, covertPropn(word.pos_)) for word in w2])\n",
    "    sentence1 = w1 - w2\n",
    "    sentence2 = w2 - w1\n",
    "    if len(sentence1) < len(sentence2): \n",
    "        t = set(sentence2)\n",
    "        sentence2 = sentence1\n",
    "        sentence1 = t\n",
    "    sentence = w1 | w2\n",
    "    if len(sentence1) == 0 or len(sentence2) == 0: return fillin\n",
    "    allsyns1 = set(leskify(w[0], w[1], sentence) for w in sentence1)\n",
    "    allsyns1 = set([a for a in allsyns1 if a])\n",
    "    if len(allsyns1) == 0: return fillin\n",
    "    ysets = [leskify(w[0], w[1], sentence) for w in sentence2]\n",
    "    ysets = [y for y in ysets if y]\n",
    "    if len(ysets) == 0: return fillin\n",
    "    maxes = [max((sim(s1, s2) or 0) for s1, s2 in product(allsyns1, [y])) for y in ysets if y]\n",
    "    return np.mean(maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15257352941176472"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = nlp(u\"I ran fast to the store to buy eggs\")\n",
    "d2 = nlp(u'He ran after waffles quickly and happily inside the shop')\n",
    "w1 = [w for w in d1 if not w.is_stop and w.pos is not 95]\n",
    "w2 = [w for w in d2 if not w.is_stop and w.pos is not 95]\n",
    "wnSim(w1, w2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepareDoc(doc):\n",
    "    return [w.lemma_ for w in doc if not w.is_stop and w.pos not in invalids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigramCounts = Counter([d for doc in docs for d in prepareDoc(doc)])\n",
    "bigramCounts = Counter([d for doc in docs for d in nltk.bigrams(prepareDoc(doc))])\n",
    "trigramCounts = Counter([d for doc in docs for d in nltk.ngrams(prepareDoc(doc), 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tfidf(w, corpus):\n",
    "    if w in corpus and corpus[w] is not 0: return 1/float(corpus[w])\n",
    "    else: return 0\n",
    "def getOverlaps(sentence1, sentence2):\n",
    "    s1 = set(sentence1)\n",
    "    s2 = set(sentence2)\n",
    "    return s1 & s2, s1 ^ s2, s1 | s2\n",
    "def tupleCounter(l):\n",
    "    d = defaultdict(int) \n",
    "    for t in l:\n",
    "        d[t[0]] += t[1]\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countQuestionPairs(docs):\n",
    "    \n",
    "    fvs = []\n",
    "    for i in range(0,len(docs),2):\n",
    "        if i % 100000 == 0: print i\n",
    "        fv = defaultdict(int) \n",
    "        d1 = docs[i]\n",
    "        d2 = docs[i+1]\n",
    "\n",
    "        s1 = set(list(str(e).lower() for e in d1.ents))\n",
    "        s2 = set(list(str(e).lower() for e in d2.ents))\n",
    "        \n",
    "        w1 = [w for w in d1 if not w.is_stop and w.pos not in invalids]\n",
    "        w2 = [w for w in d2 if not w.is_stop and w.pos not in invalids]\n",
    "        \n",
    "        p1 = [(covertPropn(word.pos_), word.lemma_) for word in w1]\n",
    "        p2 = [(covertPropn(word.pos_), word.lemma_) for word in w2]\n",
    "        \n",
    "        u1 = [word.lemma_ for word in w1]\n",
    "        u2 = [word.lemma_ for word in w2]\n",
    "        \n",
    "        total = float(len(u1) + len(u2))\n",
    "        sameents = s1 & s2\n",
    "        diffents = s1 ^ s2\n",
    "        if len(sameents) > 0:\n",
    "            fv['sameents'] = np.sum([tfidf(w, unigramCounts) for w in sameents])\n",
    "        if len(diffents) > 0:\n",
    "            fv['diffents'] = np.sum([tfidf(w, unigramCounts) for w in diffents])\n",
    "        \n",
    "        psame, pdiff, ptotal = getOverlaps(p1, p2)\n",
    "        usame, udiff, utotal = getOverlaps(u1, u2)\n",
    "        bsame, bdiff, btotal = getOverlaps(nltk.bigrams(u1), nltk.bigrams(u2))        \n",
    "        tsame, tdiff, ttotal = getOverlaps(nltk.ngrams(u1,3),nltk.ngrams(u2,3))\n",
    "#         fv['total'] = total\n",
    "        fv['usame'] = len(usame)\n",
    "        fv['udiff'] = len(udiff)\n",
    "        if len(usame) > 0:\n",
    "            fv['weightedsame'] =  np.sum([tfidf(w, unigramCounts) for w in usame])\n",
    "        if len(udiff) > 0:\n",
    "            fv['weighteddiff'] =  np.sum([tfidf(w, unigramCounts) for w in udiff])\n",
    "\n",
    "        fv.update((tupleCounter([(t[0], tfidf(t[1], unigramCounts)) for t in psame])))\n",
    "        fv.update((tupleCounter([(t[0] + '_d', tfidf(t[1], unigramCounts)) for t in pdiff])))     \n",
    "        fv['bsame'] = np.sum([tfidf(w, bigramCounts) for w in bsame])\n",
    "        fv['tsame'] = np.sum([tfidf(w, trigramCounts) for w in tsame])\n",
    "\n",
    "#         fv['wn'] = wnSim(w1, w2)\n",
    "#         if i > 100: return fvs\n",
    "#         print fv\n",
    "        fvs.append(fv)\n",
    "    return fvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n"
     ]
    }
   ],
   "source": [
    "fvs = countQuestionPairs(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getParts(d, parts):\n",
    "    out = {}\n",
    "    keys = d.keys()\n",
    "    for p in parts:\n",
    "        if p in keys: out[p] = d[p]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'ADJ_d',\n",
       " u'ADV_d',\n",
       " u'NOUN',\n",
       " u'NOUN_d',\n",
       " u'NUM_d',\n",
       " u'PRON_d',\n",
       " u'PROPN',\n",
       " u'PROPN_d',\n",
       " u'PUNCT',\n",
       " u'PUNCT_d',\n",
       " u'VERB',\n",
       " u'VERB_d',\n",
       " 'bsame',\n",
       " 'diffents',\n",
       " 'sameents',\n",
       " 'tsame',\n",
       " 'udiff',\n",
       " 'usame',\n",
       " 'weighteddiff',\n",
       " 'weightedsame'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(fvs[0].keys()) | set(fvs[1].keys()) | set(fvs[2].keys()) |set(fvs[3].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "v = DictVectorizer(sparse=False)\n",
    "X = v.fit_transform(fvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: -0.40956\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators= 50, min_samples_leaf=1, min_samples_split=8, n_jobs=-1, warm_start=True)\n",
    "scores = cross_val_score(clf, X, target, cv=3, scoring='neg_log_loss')\n",
    "print \"Log Loss: %0.5f\" % scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "Log Loss: -0.68284\n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', n_iter=5, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "Log Loss: -0.61792\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Log Loss: -0.54409\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=7,\n",
      "            min_samples_split=30, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=50, n_jobs=-1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=True)\n",
      "Log Loss: -0.42561\n",
      "LinearDiscriminantAnalysis(n_components=None, priors=None, shrinkage=None,\n",
      "              solver='svd', store_covariance=False, tol=0.0001)\n",
      "Log Loss: -0.55842\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a2136d4ded48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_log_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Log Loss: %0.5f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                                               fit_params)\n\u001b[0;32m--> 140\u001b[0;31m                       for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1026\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1028\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1029\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1081\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1082\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/ensemble/gradient_boosting.pyc\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 787\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1027\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1030\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                            self.min_impurity_split)\n\u001b[1;32m    349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clfs = [MultinomialNB(), SGDClassifier(loss='log'), LogisticRegression(), RandomForestClassifier(n_estimators= 50, min_samples_leaf=7, min_samples_split=30, n_jobs=-1, warm_start=True), LinearDiscriminantAnalysis(), GradientBoostingClassifier()]\n",
    "# clfs = [SVC(kernel='linear', probability=True)] \n",
    "\n",
    "for clf in clfs:\n",
    "    print clf\n",
    "    scores = cross_val_score(clf, X, target, cv=3, scoring='neg_log_loss')\n",
    "    print \"Log Loss: %0.5f\" % scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=.2)\n",
    "clfs = [MultinomialNB(), SGDClassifier(loss='log'), LogisticRegression(), RandomForestClassifier(n_estimators= 50, min_samples_leaf=7, min_samples_split=30, n_jobs=-1, warm_start=True), LinearDiscriminantAnalysis(), GradientBoostingClassifier()]\n",
    "clfnames  = ['RandForest', 'MNB', 'SGD','LogReg', 'RandForest', 'LDA', 'GradientBoost']\n",
    "colors = cycle(['darkorange','green', 'red', 'blue', 'k', 'p'])\n",
    "\n",
    "for (clfname, clf, color) in zip(clfnames, clfs, colors):\n",
    "    y_score = zip(*clf.fit(X_train, y_train).predict_proba(X_test))[1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "    rocauc = auc(fpr, tpr)\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color=color, lw=lw, label=clfname + ' (area = %0.2f)' % rocauc)\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Word Count Method')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"roc_wc.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read test questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_docs = []\n",
    "i = 0\n",
    "with open(test_loc, 'rb') as file_:\n",
    "    for byte_string in Doc.read_bytes(file_):\n",
    "        test_docs.append(Doc(nlp.vocab).from_bytes(byte_string))\n",
    "        i += 1\n",
    "print(type(test_docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_docs[1345288]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_fvs = countQuestionPairs(test_docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
