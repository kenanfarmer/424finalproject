{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Evaluate new Word2Vec thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy as sy\n",
    "import pandas as pd\n",
    "nlp = sy.load('en')\n",
    "\n",
    "maxt_ = 5000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 16:40:43\n",
      "100000 16:41:35\n",
      "200000 16:42:24\n",
      "300000 16:43:08\n",
      "400000 16:43:50\n",
      "500000 16:44:35\n",
      "600000 16:45:21\n",
      "700000 16:46:06\n",
      "800000 16:46:53\n"
     ]
    }
   ],
   "source": [
    "test_loc = 'test_dump.bin'\n",
    "train_loc = 'train_dump.bin'\n",
    "from datetime import datetime\n",
    "\n",
    "from spacy.tokens.doc import Doc\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "\n",
    "def clean(doc):\n",
    "    \"\"\"Removes stops from the nlp objects\"\"\"\n",
    "    b = [x for x in doc if not x.is_punct]\n",
    "    a = [x.lemma_ if not x.lemma_ == '-PRON-' else x.text for x in b ]\n",
    "    return nlp(u''.join([x + ' ' for x in a if x not in stop]))\n",
    "\n",
    "\n",
    "test_docs = []\n",
    "train_docs = []\n",
    "i = 0\n",
    "#print datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "with open(train_loc, 'rb') as file_:\n",
    "    for byte_string in Doc.read_bytes(file_):\n",
    "        if i%100000 == 0: print i, datetime.now().strftime('%H:%M:%S')\n",
    "        train_docs.append(clean(Doc(nlp.vocab).from_bytes(byte_string)))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Custom Word Movers\n",
    "two sentences and for each word in sent1 find the nearest word vec in sent2. Take that distance and sum over all words in sent1 and then words in sent 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def my_wmd(doc1,doc2):\n",
    "    touched = False\n",
    "    t_sum = 0.0\n",
    "    for x in doc1:\n",
    "        a = x.vector\n",
    "        min_a = np.inf\n",
    "        for y in doc2:\n",
    "            b = y.vector\n",
    "            dist = np.linalg.norm(a-b)    \n",
    "            if dist < min_a:\n",
    "                touched = True\n",
    "                min_a = dist\n",
    "        t_sum = t_sum + min_a\n",
    "    for x in doc2:\n",
    "        a = x.vector\n",
    "        min_a = np.inf\n",
    "        for y in doc1:\n",
    "            b = y.vector\n",
    "            dist = np.linalg.norm(a-b)    \n",
    "            if dist < min_a:\n",
    "                touched = True\n",
    "                min_a = dist\n",
    "        t_sum = t_sum + min_a  \n",
    "    if touched:\n",
    "        return t_sum\n",
    "    else:\n",
    "        return maxt_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 17:00:08\n",
      "50000 17:01:08\n",
      "100000 17:02:06\n",
      "150000 17:03:02\n",
      "200000 17:04:01\n",
      "250000 17:05:01\n",
      "300000 17:05:57\n",
      "350000 17:06:57\n",
      "400000 17:07:54\n",
      "yay\n"
     ]
    }
   ],
   "source": [
    "d = []\n",
    "ct = 0\n",
    "for q1,q2 in [(train_docs[2*i],train_docs[2*i+1]) for i in range(len(train_docs)/2)]:\n",
    "    d.append({ 'kfwmd': my_wmd(q1,q2) })\n",
    "    if ct % 50000 == 0: print ct, datetime.now().strftime('%H:%M:%S')\n",
    "    ct = ct+1\n",
    "features = pd.DataFrame(d)\n",
    "print \"yay\"\n",
    "features.to_csv('kfwmd_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Entities Word Mover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ent_wmd(doc1,doc2):\n",
    "    touched = False\n",
    "    t_sum = 0.0\n",
    "    for x in doc1.ents:\n",
    "        a = x.vector\n",
    "        min_a = np.inf\n",
    "        for y in doc2:\n",
    "            b = y.vector\n",
    "            dist = np.linalg.norm(a-b)    \n",
    "            if dist < min_a:\n",
    "                touched = True\n",
    "                min_a = dist\n",
    "        t_sum = t_sum + min_a\n",
    "    for x in doc2.ents:\n",
    "        a = x.vector\n",
    "        min_a = np.inf\n",
    "        for y in doc1:\n",
    "            b = y.vector\n",
    "            dist = np.linalg.norm(a-b)    \n",
    "            if dist < min_a:\n",
    "                touched = True\n",
    "                min_a = dist\n",
    "        t_sum = t_sum + min_a   \n",
    "    if touched:\n",
    "        return t_sum\n",
    "    else:\n",
    "        return maxt_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 17:08:02\n",
      "50000 17:08:06\n",
      "100000 17:08:09\n",
      "150000 17:08:13\n",
      "200000 17:08:17\n",
      "250000 17:08:20\n",
      "300000 17:08:24\n",
      "350000 17:08:27\n",
      "400000 17:08:30\n",
      "yay\n"
     ]
    }
   ],
   "source": [
    "d = []\n",
    "ct = 0\n",
    "for q1,q2 in [(train_docs[2*i],train_docs[2*i+1]) for i in range(len(train_docs)/2)]:\n",
    "    d.append({ 'kfwmd': ent_wmd(q1,q2) })\n",
    "    if ct % 50000 == 0: print ct, datetime.now().strftime('%H:%M:%S')\n",
    "    ct = ct+1\n",
    "features = pd.DataFrame(d)\n",
    "print \"yay\"\n",
    "features.to_csv('entwmd_1.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Unique word mover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def unique_wmd(d1,d2):\n",
    "    touched = False\n",
    "    unique_doc1 = [x.text for x in d1 if x not in d2]\n",
    "    unique_doc2 = [x.text for x in d2 if x not in d1]\n",
    "    doc1 = nlp(u''.join(unique_doc1))\n",
    "    doc2 = nlp(u''.join(unique_doc2))\n",
    "    t_sum = 0.0\n",
    "    for x in doc1:\n",
    "        a = x.vector\n",
    "        min_a = np.inf\n",
    "        for y in doc2:\n",
    "            b = y.vector\n",
    "            dist = np.linalg.norm(a-b)    \n",
    "            if dist < min_a:\n",
    "                touched = True\n",
    "                min_a = dist\n",
    "        t_sum = t_sum + min_a\n",
    "    for x in doc2:\n",
    "        a = x.vector\n",
    "        min_a = np.inf\n",
    "        for y in doc1:\n",
    "            b = y.vector\n",
    "            dist = np.linalg.norm(a-b)    \n",
    "            if dist < min_a:\n",
    "                touched = True\n",
    "                min_a = dist\n",
    "        t_sum = t_sum + min_a   \n",
    "    if touched:\n",
    "        return t_sum\n",
    "    else:\n",
    "        return maxt_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 17:10:22\n",
      "50000 17:10:43\n",
      "100000 17:11:01\n",
      "150000 17:11:19\n",
      "200000 17:11:37\n",
      "250000 17:11:54\n",
      "300000 17:12:12\n",
      "350000 17:12:30\n",
      "400000 17:12:48\n",
      "yay\n"
     ]
    }
   ],
   "source": [
    "d = []\n",
    "ct = 0\n",
    "for q1,q2 in [(train_docs[2*i],train_docs[2*i+1]) for i in range(len(train_docs)/2)]:\n",
    "    d.append({ 'kfwmd': unique_wmd(q1,q2) })\n",
    "    if ct % 50000 == 0: print ct, datetime.now().strftime('%H:%M:%S')\n",
    "    ct = ct+1\n",
    "features = pd.DataFrame(d)\n",
    "print \"yay\"\n",
    "features.to_csv('unqwmd_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Verbs and Nouns Word Mover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 17:12:58\n",
      "50000 17:13:20\n",
      "100000 17:13:40\n",
      "150000 17:14:01\n",
      "200000 17:14:21\n",
      "250000 17:14:41\n",
      "300000 17:15:00\n",
      "350000 17:15:19\n",
      "400000 17:15:39\n",
      "yay\n"
     ]
    }
   ],
   "source": [
    "# ******** RUN CELL BELOW FIRST************\n",
    "d = []\n",
    "ct = 0\n",
    "for q1,q2 in [(train_docs[2*i],train_docs[2*i+1]) for i in range(len(train_docs)/2)]:\n",
    "    d.append({ 'kfwmd': pos_wmd(q1,q2,['VERB','NOUN','PROPN',\"PRON\"]) })\n",
    "    if ct % 50000 == 0: print ct, datetime.now().strftime('%H:%M:%S')\n",
    "    ct = ct+1\n",
    "features = pd.DataFrame(d)\n",
    "print \"yay\"\n",
    "features.to_csv('vnwmd_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## POS features\n",
    "- Verb\n",
    "- Noun\n",
    "- PROPN\n",
    "- PROPN + NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pos_wmd(d1,d2,check):\n",
    "    looking = check\n",
    "    touched = False\n",
    "    unique_doc1 = [x.text for x in d1 if x.pos_ in looking]\n",
    "    unique_doc2 = [x.text for x in d2 if x.pos_ in looking]\n",
    "    doc1 = nlp(u''.join(unique_doc1))\n",
    "    doc2 = nlp(u''.join(unique_doc2))\n",
    "    t_sum = 0.0\n",
    "    for x in doc1:\n",
    "        a = x.vector\n",
    "        min_a = np.inf\n",
    "        for y in doc2:\n",
    "            b = y.vector\n",
    "            dist = np.linalg.norm(a-b)    \n",
    "            if dist < min_a:\n",
    "                touched = True\n",
    "                min_a = dist\n",
    "        t_sum = t_sum + min_a\n",
    "    for x in doc2:\n",
    "        a = x.vector\n",
    "        min_a = np.inf\n",
    "        for y in doc1:\n",
    "            b = y.vector\n",
    "            dist = np.linalg.norm(a-b)    \n",
    "            if dist < min_a:\n",
    "                touched = True\n",
    "                min_a = dist\n",
    "        t_sum = t_sum + min_a   \n",
    "    if touched:\n",
    "        return t_sum\n",
    "    else:\n",
    "        return maxt_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 11:56:59\n",
      "50000 11:57:41\n",
      "100000 11:58:23\n",
      "150000 11:59:05\n",
      "200000 11:59:48\n",
      "250000 12:00:31\n",
      "300000 12:01:13\n",
      "350000 12:01:55\n",
      "400000 12:02:37\n",
      "yay\n"
     ]
    }
   ],
   "source": [
    "d = []\n",
    "ct = 0\n",
    "for q1,q2 in [(train_docs[2*i],train_docs[2*i+1]) for i in range(len(train_docs)/2)]:\n",
    "    # either cos, euclid or l2\n",
    "    d.append({ \n",
    "        'noun': pos_wmd(q1, q2, [\"NOUN\"]),\n",
    "        'verb': pos_wmd(q1, q2, [\"VERB\"]),\n",
    "        'prop': pos_wmd(q1, q2, [\"PROPN\"]), \n",
    "        'pron': pos_wmd(q1, q2, [\"NOUN\",\"PROPN\"])\n",
    "    })\n",
    "    if ct % 50000 == 0: print ct, datetime.now().strftime('%H:%M:%S')\n",
    "    ct = ct+1\n",
    "features = pd.DataFrame(d)\n",
    "print \"yay\"\n",
    "features.to_csv('pos_wmd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def summation(doc1,doc2):\n",
    "    sum_a = np.zeros(300,)\n",
    "    sum_b = np.zeros(300,)\n",
    "    for x in doc1:\n",
    "        sum_a = sum_a + x.vector\n",
    "    for x in doc2:\n",
    "        sum_b = sum_b + x.vector \n",
    "    if len(doc1)>0 and len(doc2)>0:\n",
    "        return np.linalg.norm(sum_a - sum_b)   \n",
    "    else:\n",
    "        return maxt_/2\n",
    "    \n",
    "def pos_sum(d1,d2,looking):\n",
    "    touched = False\n",
    "    unique_doc1 = [x.text for x in d1 if x.pos_ in looking]\n",
    "    unique_doc2 = [x.text for x in d2 if x.pos_ in looking]\n",
    "    doc1 = nlp(u''.join(unique_doc1))\n",
    "    doc2 = nlp(u''.join(unique_doc2))\n",
    "    t_sum = 0.0\n",
    "    sum_a = np.zeros(300,)\n",
    "    sum_b = np.zeros(300,)\n",
    "    for x in doc1:\n",
    "        sum_a = sum_a + x.vector\n",
    "    for x in doc2:\n",
    "        sum_b = sum_b + x.vector \n",
    "    if len(doc1)>0 and len(doc2)>0:\n",
    "        return np.linalg.norm(sum_a - sum_b)   \n",
    "    else:\n",
    "        return maxt_/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "(step step guide invest share market india , step step guide invest share market )\n",
      "18.7169675827\n"
     ]
    }
   ],
   "source": [
    "print summation(train_docs[0], train_docs[1])\n",
    "print (train_docs[0], train_docs[1])\n",
    "print my_wmd(train_docs[100], train_docs[101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 17:15:42\n",
      "50000 17:17:02\n",
      "100000 17:18:21\n",
      "150000 17:19:40\n",
      "200000 17:20:59\n",
      "250000 17:22:18\n",
      "300000 17:23:37\n",
      "350000 17:24:57\n",
      "400000 17:26:16\n",
      "yay\n"
     ]
    }
   ],
   "source": [
    "d = []\n",
    "ct = 0\n",
    "for q1,q2 in [(train_docs[2*i],train_docs[2*i+1]) for i in range(len(train_docs)/2)]:\n",
    "    # either cos, euclid or l2\n",
    "    d.append({ \n",
    "        'nwmd': pos_wmd(q1, q2, [\"NOUN\"]),\n",
    "        'vwmd': pos_wmd(q1, q2, [\"VERB\"]),\n",
    "        'pwmd': pos_wmd(q1, q2, [\"PROPN\"]), \n",
    "        'pnwmd': pos_wmd(q1, q2, [\"NOUN\",\"PROPN\"]),\n",
    "        'nsum': pos_sum(q1, q2, [\"NOUN\"]),\n",
    "        'vsum': pos_sum(q1, q2, [\"VERB\"]),\n",
    "        'psum': pos_sum(q1, q2, [\"PROPN\"]), \n",
    "        'psum': pos_sum(q1, q2, [\"NOUN\",\"PROPN\"]),\n",
    "    })\n",
    "    if ct % 50000 == 0: print ct, datetime.now().strftime('%H:%M:%S')\n",
    "    ct = ct+1\n",
    "features = pd.DataFrame(d)\n",
    "print \"yay\"\n",
    "features.to_csv('pos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
