{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Evaluate new Word2Vec thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy as sy\n",
    "import pandas as pd\n",
    "nlp = sy.load('en')\n",
    "import textacy as ty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 11:37:27\n",
      "100000 11:38:18\n",
      "200000 11:39:03\n",
      "300000 11:39:47\n",
      "400000 11:40:31\n",
      "500000 11:41:14\n",
      "600000 11:42:00\n",
      "700000 11:42:47\n",
      "800000 11:43:35\n"
     ]
    }
   ],
   "source": [
    "test_loc = 'test_dump.bin'\n",
    "train_loc = 'train_dump.bin'\n",
    "from datetime import datetime\n",
    "\n",
    "from spacy.tokens.doc import Doc\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "\n",
    "def clean(doc):\n",
    "    \"\"\"Removes stops from the nlp objects\"\"\"\n",
    "    b = [x for x in doc if not x.is_punct]\n",
    "    a = [x.lemma_ if not x.lemma_ == '-PRON-' else x.text for x in b ]\n",
    "    return nlp(u''.join([x + ' ' for x in a if x not in stop]))\n",
    "\n",
    "\n",
    "test_docs = []\n",
    "train_docs = []\n",
    "i = 0\n",
    "#print datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "with open(train_loc, 'rb') as file_:\n",
    "    for byte_string in Doc.read_bytes(file_):\n",
    "        if i%100000 == 0: print i, datetime.now().strftime('%H:%M:%S')\n",
    "        train_docs.append(clean(Doc(nlp.vocab).from_bytes(byte_string)))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Custom Word Movers\n",
    "two sentences and for each word in sent1 find the nearest word vec in sent2. Take that distance and sum over all words in sent1 and then words in sent 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def my_wmd(doc1,doc2):\n",
    "    t_sum = 0.0\n",
    "    for x in doc1:\n",
    "        a = x.vector\n",
    "        min_a = np.inf\n",
    "        for y in doc2:\n",
    "            b = y.vector\n",
    "            dist = np.linalg.norm(a-b)    \n",
    "            if dist < min_a:\n",
    "                min_a = dist\n",
    "        t_sum = t_sum + min_a\n",
    "    for x in doc2:\n",
    "        a = x.vector\n",
    "        min_a = np.inf\n",
    "        for y in doc1:\n",
    "            b = y.vector\n",
    "            dist = np.linalg.norm(a-b)    \n",
    "            if dist < min_a:\n",
    "                min_a = dist\n",
    "        t_sum = t_sum + min_a   \n",
    "    return t_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "d = []\n",
    "ct = 0\n",
    "for q1,q2 in [(train_docs[2*i],train_docs[2*i+1]) for i in range(len(train_docs)/2)]:\n",
    "    d.append({ 'kfwmd': my_wmd(q1,q2) })\n",
    "    if ct % 50000 == 0: print ct, datetime.now().strftime('%H:%M:%S')\n",
    "    ct = ct+1\n",
    "features = pd.DataFrame(d)\n",
    "print \"yay\"\n",
    "features.to_csv('kfwmd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Entities Word Mover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def ent_wmd(doc1,doc2):\n",
    "    t_sum = 0.0\n",
    "    for x in doc1.ents:\n",
    "        a = x.vector\n",
    "        min_a = np.inf\n",
    "        for y in doc2:\n",
    "            b = y.vector\n",
    "            dist = np.linalg.norm(a-b)    \n",
    "            if dist < min_a:\n",
    "                min_a = dist\n",
    "        t_sum = t_sum + min_a\n",
    "    for x in doc2.ents:\n",
    "        a = x.vector\n",
    "        min_a = np.inf\n",
    "        for y in doc1:\n",
    "            b = y.vector\n",
    "            dist = np.linalg.norm(a-b)    \n",
    "            if dist < min_a:\n",
    "                min_a = dist\n",
    "        t_sum = t_sum + min_a   \n",
    "    return t_sum   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "d = []\n",
    "ct = 0\n",
    "for q1,q2 in [(train_docs[2*i],train_docs[2*i+1]) for i in range(len(train_docs)/2)]:\n",
    "    d.append({ 'kfwmd': ent_wmd(q1,q2) })\n",
    "    if ct % 50000 == 0: print ct, datetime.now().strftime('%H:%M:%S')\n",
    "    ct = ct+1\n",
    "features = pd.DataFrame(d)\n",
    "print \"yay\"\n",
    "features.to_csv('entwmd.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Unique word mover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def unique_wmd(d1,d2):\n",
    "    unique_doc1 = [x.text for x in d1 if x not in d2]\n",
    "    unique_doc2 = [x.text for x in d2 if x not in d1]\n",
    "    doc1 = nlp(u''.join(unique_doc1))\n",
    "    doc2 = nlp(u''.join(unique_doc2))\n",
    "    t_sum = 0.0\n",
    "    for x in doc1:\n",
    "        a = x.vector\n",
    "        min_a = np.inf\n",
    "        for y in doc2:\n",
    "            b = y.vector\n",
    "            dist = np.linalg.norm(a-b)    \n",
    "            if dist < min_a:\n",
    "                min_a = dist\n",
    "        t_sum = t_sum + min_a\n",
    "    for x in doc2:\n",
    "        a = x.vector\n",
    "        min_a = np.inf\n",
    "        for y in doc1:\n",
    "            b = y.vector\n",
    "            dist = np.linalg.norm(a-b)    \n",
    "            if dist < min_a:\n",
    "                min_a = dist\n",
    "        t_sum = t_sum + min_a   \n",
    "    return t_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "d = []\n",
    "ct = 0\n",
    "for q1,q2 in [(train_docs[2*i],train_docs[2*i+1]) for i in range(len(train_docs)/2)]:\n",
    "    d.append({ 'kfwmd': vn_wmd(q1,q2) })\n",
    "    if ct % 50000 == 0: print ct, datetime.now().strftime('%H:%M:%S')\n",
    "    ct = ct+1\n",
    "features = pd.DataFrame(d)\n",
    "print \"yay\"\n",
    "features.to_csv('unqwmd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Verbs and Nouns Word Mover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def vn_wmd(d1,d2):\n",
    "    looking = ['NOUN','VERB','PRON','PROPN']\n",
    "    unique_doc1 = [x.text for x in d1 if x.pos_ in looking]\n",
    "    unique_doc2 = [x.text for x in d2 if x.pos_ in looking]\n",
    "    doc1 = nlp(u''.join(unique_doc1))\n",
    "    doc2 = nlp(u''.join(unique_doc2))\n",
    "    t_sum = 0.0\n",
    "    for x in doc1:\n",
    "        a = x.vector\n",
    "        min_a = np.inf\n",
    "        for y in doc2:\n",
    "            b = y.vector\n",
    "            dist = np.linalg.norm(a-b)    \n",
    "            if dist < min_a:\n",
    "                min_a = dist\n",
    "        t_sum = t_sum + min_a\n",
    "    for x in doc2:\n",
    "        a = x.vector\n",
    "        min_a = np.inf\n",
    "        for y in doc1:\n",
    "            b = y.vector\n",
    "            dist = np.linalg.norm(a-b)    \n",
    "            if dist < min_a:\n",
    "                min_a = dist\n",
    "        t_sum = t_sum + min_a   \n",
    "    return t_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "d = []\n",
    "ct = 0\n",
    "for q1,q2 in [(train_docs[2*i],train_docs[2*i+1]) for i in range(len(train_docs)/2)]:\n",
    "    d.append({ 'kfwmd': vn_wmd(q1,q2) })\n",
    "    if ct % 50000 == 0: print ct, datetime.now().strftime('%H:%M:%S')\n",
    "    ct = ct+1\n",
    "features = pd.DataFrame(d)\n",
    "print \"yay\"\n",
    "features.to_csv('vnwmd.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## POS features\n",
    "- Verb\n",
    "- Noun\n",
    "- PROPN\n",
    "- PROPN + NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def pos_wmd(d1,d2,check):\n",
    "    looking = check\n",
    "    unique_doc1 = [x.text for x in d1 if x.pos_ in looking]\n",
    "    unique_doc2 = [x.text for x in d2 if x.pos_ in looking]\n",
    "    doc1 = nlp(u''.join(unique_doc1))\n",
    "    doc2 = nlp(u''.join(unique_doc2))\n",
    "    t_sum = 0.0\n",
    "    for x in doc1:\n",
    "        a = x.vector\n",
    "        min_a = np.inf\n",
    "        for y in doc2:\n",
    "            b = y.vector\n",
    "            dist = np.linalg.norm(a-b)    \n",
    "            if dist < min_a:\n",
    "                max_a = dist\n",
    "        t_sum = t_sum + max_a\n",
    "    for x in doc2:\n",
    "        a = x.vector\n",
    "        max_a = np.inf\n",
    "        for y in doc1:\n",
    "            b = y.vector\n",
    "            dist = np.linalg.norm(a-b)    \n",
    "            if dist < max_a:\n",
    "                max_a = dist\n",
    "        t_sum = t_sum + max_a   \n",
    "    return t_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 11:56:59\n",
      "50000 11:57:41\n",
      "100000 11:58:23\n",
      "150000 11:59:05\n",
      "200000 11:59:48\n",
      "250000 12:00:31\n",
      "300000 12:01:13\n",
      "350000 12:01:55\n",
      "400000 12:02:37\n",
      "yay\n"
     ]
    }
   ],
   "source": [
    "d = []\n",
    "ct = 0\n",
    "for q1,q2 in [(train_docs[2*i],train_docs[2*i+1]) for i in range(len(train_docs)/2)]:\n",
    "    # either cos, euclid or l2\n",
    "    d.append({ \n",
    "        'noun': pos_wmd(q1, q2, [\"NOUN\"]),\n",
    "        'verb': pos_wmd(q1, q2, [\"VERB\"]),\n",
    "        'prop': pos_wmd(q1, q2, [\"PROPN\"]), \n",
    "        'pron': pos_wmd(q1, q2, [\"NOUN\",\"PROPN\"])\n",
    "    })\n",
    "    if ct % 50000 == 0: print ct, datetime.now().strftime('%H:%M:%S')\n",
    "    ct = ct+1\n",
    "features = pd.DataFrame(d)\n",
    "print \"yay\"\n",
    "features.to_csv('pos_wmd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
