{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens.doc import Doc\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_loc = 'test_dump.bin'\n",
    "train_loc = 'train_dump.bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404290, 6) (2345796, 3)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../data/train.csv').fillna('')\n",
    "test = pd.read_csv('../data/test.csv').fillna('')\n",
    "print train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write training questions\n",
    "In the order they appear, not the order of their ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 What is the step by step guide to invest in share market?\n",
      "10000 Is it safe for a woman to travel alone in Japan?\n",
      "20000 What triggers you the most when you play video games?\n",
      "30000 Is domino's pizza halal?\n",
      "40000 How should I start learning Python for Data Science?\n",
      "50000 Why is cloning considered unethical?\n",
      "60000 How do you get rid of a virus on an iPhone?\n",
      "70000 What are some teenage cake ideas?\n",
      "80000 How do I recover deleted files on an Android phone or tablet?\n",
      "90000 Which are the best Hollywood movies of 2016?\n",
      "100000 What is the process of getting a surgical residency in UK after completing MBBS from India?\n",
      "110000 How do I become an entrepreneur?\n",
      "120000 How can I become a billionaire?\n",
      "130000 What is it like to grow up in Japan, SIngapore and Hong Kong?\n",
      "140000 Which is a good car in the range of 2-3lacs on Delhi road?\n",
      "150000 How do I grow my hair really fast and easiest way?\n",
      "160000 What are the career options after graduating with a B.A. in philosophy?\n",
      "170000 Is welfare a citizenship right?\n",
      "180000 How do you find a Spiritual Guru?\n",
      "190000 What is the best SEO management company in India?\n",
      "200000 Can Pakistan destroy an Indian aircraft carrier during a war?\n",
      "210000 What does it look like when someone blocks you on badoo?\n",
      "220000 How do I best way to get over an ex?\n",
      "230000 Taking meth through the rectal, is it a better high?\n",
      "240000 What's the evil truth of life?\n",
      "250000 Who would win a war out of the United States and Russia?\n",
      "260000 What is that one incident that changed your life for better?\n",
      "270000 Which movie had the first same-sex kiss?\n",
      "280000 How is the word 'although' used in a sentence?\n",
      "290000 How will abolishing Rs. 500 and Rs. 1000 notes affect the real estate businesses in India?\n",
      "300000 What is the difference between neural circuit and neural system?\n",
      "310000 What is the poorest country in Asia, and how does its death rate compare to the poorest country in Oceania?\n",
      "320000 What is the most technologically advanced credit union in San Francisco?\n",
      "330000 Which teams are likely to win EPL 2016_2017?\n",
      "340000 What if you want to do everything?\n",
      "350000 How can you give dogs Benadryl to calm them down?\n",
      "360000 What does the typical Finnish house look like?\n",
      "370000 Does Israel have a movie industry?\n",
      "380000 How do I compare Albuquerque New Mexico to Phoenix AZ?\n",
      "390000 What should I gift to my girlfriend for Christmas?\n",
      "400000 Can WordPress be used to create a site like Reddit?\n"
     ]
    }
   ],
   "source": [
    "# with open(train_loc, 'wb') as file_:\n",
    "#     for idx, question in enumerate(train_array):\n",
    "#         if idx % 10000 == 0: print(idx, question)\n",
    "#         file_.write(nlp(question.decode('utf-8')).to_bytes())\n",
    "with open(train_loc, 'wb') as file_:\n",
    "    for i in range(len(train)):\n",
    "        f = train.loc[i]\n",
    "        if i % 10000 == 0: print i, f['question2']\n",
    "        file_.write(nlp(f['question1'].decode('utf-8')).to_bytes())\n",
    "        file_.write(nlp(f['question2'].decode('utf-8')).to_bytes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read training data\n",
    "Elements $(2n, 2n+1)$ are the questions for pair $n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-13 16:58:08\n",
      "0 2017-05-13 16:58:08\n",
      "10000 2017-05-13 16:58:12\n",
      "20000 2017-05-13 16:58:14\n",
      "30000 2017-05-13 16:58:15\n",
      "40000 2017-05-13 16:58:16\n",
      "50000 2017-05-13 16:58:17\n",
      "60000 2017-05-13 16:58:18\n",
      "70000 2017-05-13 16:58:19\n",
      "80000 2017-05-13 16:58:20\n",
      "90000 2017-05-13 16:58:22\n",
      "100000 2017-05-13 16:58:23\n",
      "110000 2017-05-13 16:58:24\n",
      "120000 2017-05-13 16:58:25\n",
      "130000 2017-05-13 16:58:27\n",
      "140000 2017-05-13 16:58:28\n",
      "150000 2017-05-13 16:58:29\n",
      "160000 2017-05-13 16:58:31\n",
      "170000 2017-05-13 16:58:32\n",
      "180000 2017-05-13 16:58:33\n",
      "190000 2017-05-13 16:58:34\n",
      "200000 2017-05-13 16:58:36\n",
      "210000 2017-05-13 16:58:38\n",
      "220000 2017-05-13 16:58:39\n",
      "230000 2017-05-13 16:58:40\n",
      "240000 2017-05-13 16:58:41\n",
      "250000 2017-05-13 16:58:42\n",
      "260000 2017-05-13 16:58:44\n",
      "270000 2017-05-13 16:58:45\n",
      "280000 2017-05-13 16:58:46\n",
      "290000 2017-05-13 16:58:48\n",
      "300000 2017-05-13 16:58:49\n",
      "310000 2017-05-13 16:58:50\n",
      "320000 2017-05-13 16:58:51\n",
      "330000 2017-05-13 16:58:53\n",
      "340000 2017-05-13 16:58:54\n",
      "350000 2017-05-13 16:58:55\n",
      "360000 2017-05-13 16:58:56\n",
      "370000 2017-05-13 16:58:58\n",
      "380000 2017-05-13 16:58:59\n",
      "390000 2017-05-13 16:59:00\n",
      "400000 2017-05-13 16:59:02\n",
      "410000 2017-05-13 16:59:03\n",
      "420000 2017-05-13 16:59:11\n",
      "430000 2017-05-13 16:59:12\n",
      "440000 2017-05-13 16:59:14\n",
      "450000 2017-05-13 16:59:15\n",
      "460000 2017-05-13 16:59:16\n",
      "470000 2017-05-13 16:59:17\n",
      "480000 2017-05-13 16:59:18\n",
      "490000 2017-05-13 16:59:19\n",
      "500000 2017-05-13 16:59:20\n",
      "510000 2017-05-13 16:59:21\n",
      "520000 2017-05-13 16:59:22\n",
      "530000 2017-05-13 16:59:31\n",
      "540000 2017-05-13 16:59:33\n",
      "550000 2017-05-13 16:59:35\n",
      "560000 2017-05-13 16:59:36\n",
      "570000 2017-05-13 16:59:38\n",
      "580000 2017-05-13 16:59:40\n",
      "590000 2017-05-13 16:59:42\n",
      "600000 2017-05-13 16:59:43\n",
      "610000 2017-05-13 16:59:44\n",
      "620000 2017-05-13 16:59:45\n",
      "630000 2017-05-13 16:59:47\n",
      "640000 2017-05-13 16:59:48\n",
      "650000 2017-05-13 16:59:49\n",
      "660000 2017-05-13 16:59:51\n",
      "670000 2017-05-13 17:00:10\n",
      "680000 2017-05-13 17:00:14\n",
      "690000 2017-05-13 17:00:16\n",
      "700000 2017-05-13 17:00:17\n",
      "710000 2017-05-13 17:00:19\n",
      "720000 2017-05-13 17:00:21\n",
      "730000 2017-05-13 17:00:22\n",
      "740000 2017-05-13 17:00:24\n",
      "750000 2017-05-13 17:00:25\n",
      "760000 2017-05-13 17:00:26\n",
      "770000 2017-05-13 17:00:27\n",
      "780000 2017-05-13 17:00:29\n",
      "790000 2017-05-13 17:00:30\n",
      "800000 2017-05-13 17:00:31\n",
      "2017-05-13 17:00:32\n",
      "<type 'spacy.tokens.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "i = 0\n",
    "print datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "with open(train_loc, 'rb') as file_:\n",
    "    for byte_string in Doc.read_bytes(file_):\n",
    "        if i%10000 == 0: print i, datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        docs.append(Doc(nlp.vocab).from_bytes(byte_string))\n",
    "        i += 1\n",
    "#         if i == 10: break\n",
    "print datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print(type(docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I lose weight quickly?\n",
      "how\n",
      "can\n",
      "-PRON-\n",
      "lose\n",
      "weight\n",
      "quickly\n",
      "?\n"
     ]
    }
   ],
   "source": [
    "print(docs[23986])\n",
    "for word in docs[23986]:\n",
    "    print(word.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write test questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2345796\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n",
      "500000\n",
      "510000\n",
      "520000\n",
      "530000\n",
      "540000\n",
      "550000\n",
      "560000\n",
      "570000\n",
      "580000\n",
      "590000\n",
      "600000\n",
      "610000\n",
      "620000\n",
      "630000\n",
      "640000\n",
      "650000\n",
      "660000\n",
      "670000\n",
      "680000\n",
      "690000\n",
      "700000\n",
      "710000\n",
      "720000\n",
      "730000\n",
      "740000\n",
      "750000\n",
      "760000\n",
      "770000\n",
      "780000\n",
      "790000\n",
      "800000\n",
      "810000\n",
      "820000\n",
      "830000\n",
      "840000\n",
      "850000\n",
      "860000\n",
      "870000\n",
      "880000\n",
      "890000\n",
      "900000\n",
      "910000\n",
      "920000\n",
      "930000\n",
      "940000\n",
      "950000\n",
      "960000\n",
      "970000\n",
      "980000\n",
      "990000\n",
      "1000000\n",
      "1010000\n",
      "1020000\n",
      "1030000\n",
      "1040000\n",
      "1050000\n",
      "1060000\n",
      "1070000\n",
      "1080000\n",
      "1090000\n",
      "1100000\n",
      "1110000\n",
      "1120000\n",
      "1130000\n",
      "1140000\n",
      "1150000\n",
      "1160000\n",
      "1170000\n",
      "1180000\n",
      "1190000\n",
      "1200000\n",
      "1210000\n",
      "1220000\n",
      "1230000\n",
      "1240000\n",
      "1250000\n",
      "1260000\n",
      "1270000\n",
      "1280000\n",
      "1290000\n",
      "1300000\n",
      "1310000\n",
      "1320000\n",
      "1330000\n",
      "1340000\n",
      "1350000\n",
      "1360000\n",
      "1370000\n",
      "1380000\n",
      "1390000\n",
      "1400000\n",
      "1410000\n",
      "1420000\n",
      "1430000\n",
      "1440000\n",
      "1450000\n",
      "1460000\n",
      "1470000\n",
      "1480000\n",
      "1490000\n",
      "1500000\n",
      "1510000\n",
      "1520000\n",
      "1530000\n",
      "1540000\n",
      "1550000\n",
      "1560000\n",
      "1570000\n",
      "1580000\n",
      "1590000\n",
      "1600000\n",
      "1610000\n",
      "1620000\n",
      "1630000\n",
      "1640000\n",
      "1650000\n",
      "1660000\n",
      "1670000\n",
      "1680000\n",
      "1690000\n",
      "1700000\n",
      "1710000\n",
      "1720000\n",
      "1730000\n",
      "1740000\n",
      "1750000\n",
      "1760000\n",
      "1770000\n",
      "1780000\n",
      "1790000\n",
      "1800000\n",
      "1810000\n",
      "1820000\n",
      "1830000\n",
      "1840000\n",
      "1850000\n",
      "1860000\n",
      "1870000\n",
      "1880000\n",
      "1890000\n",
      "1900000\n",
      "1910000\n",
      "1920000\n",
      "1930000\n",
      "1940000\n",
      "1950000\n",
      "1960000\n",
      "1970000\n",
      "1980000\n",
      "1990000\n",
      "2000000\n",
      "2010000\n",
      "2020000\n",
      "2030000\n",
      "2040000\n",
      "2050000\n",
      "2060000\n",
      "2070000\n",
      "2080000\n",
      "2090000\n",
      "2100000\n",
      "2110000\n",
      "2120000\n",
      "2130000\n",
      "2140000\n",
      "2150000\n",
      "2160000\n",
      "2170000\n",
      "2180000\n",
      "2190000\n",
      "2200000\n",
      "2210000\n",
      "2220000\n",
      "2230000\n",
      "2240000\n",
      "2250000\n",
      "2260000\n",
      "2270000\n",
      "2280000\n",
      "2290000\n",
      "2300000\n",
      "2310000\n",
      "2320000\n",
      "2330000\n",
      "2340000\n"
     ]
    }
   ],
   "source": [
    "print len(test)\n",
    "with open(test_loc, 'wb') as file_:\n",
    "    for i in range(len(test)):\n",
    "        if i % 10000 == 0: print i\n",
    "        f = test.loc[i]\n",
    "        file_.write(nlp(f['question1'].decode('utf-8')).to_bytes())\n",
    "        file_.write(nlp(f['question2'].decode('utf-8')).to_bytes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read test questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-07210cd5dcdd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbyte_string\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtest_docs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_docs = []\n",
    "i = 0\n",
    "with open(test_loc, 'rb') as file_:\n",
    "    for byte_string in Doc.read_bytes(file_):\n",
    "        test_docs.append(Doc(nlp.vocab).from_bytes(byte_string))\n",
    "        i += 1\n",
    "print(type(test_docs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_docs[1345288]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testloc = 'test_serialize.bin'\n",
    "with open(testloc, 'wb') as file_:\n",
    "    file_.write(nlp(u'This is a document.').to_bytes())\n",
    "    file_.write(nlp(u'This is another.').to_bytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = []\n",
    "with open(testloc, 'rb') as file_:\n",
    "    for byte_string in Doc.read_bytes(file_):\n",
    "        docs.append(Doc(nlp.vocab).from_bytes(byte_string))\n",
    "assert len(docs) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({u'.': 1, u'a': 1, u'be': 1, u'document': 1, u'this': 1})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = []\n",
    "for word in p:\n",
    "#     if word.is_stop: continue\n",
    "    bow.append(word.lemma_)\n",
    "Counter(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_id                                                     20\n",
      "question1    How matter at MIT? Will performing poorly in 1...\n",
      "question2    I have passed 5 AP tests with scores trump 5. ...\n",
      "Name: 20, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(test.loc[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are some good books to read about Islamic philosophy?\n",
      "what be some good book to read about islamic philosophy ?\n"
     ]
    }
   ],
   "source": [
    "doc = docs[24890]\n",
    "print doc\n",
    "print(' '.join(word.lemma_ for word in doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lemmas = []\n",
    "for idx, doc in enumerate(docs):\n",
    "    lemma = []\n",
    "    for word in doc:\n",
    "        if not word.is_punct: lemma.append(word.lemma_)\n",
    "    lemmas.append(lemma)\n",
    "    if idx == 20: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(type(lemmas[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
